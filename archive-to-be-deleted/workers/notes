
WORKER COMPONENTS
runc
container networking plugins
containerd
kubelet
kube-proxy

# DID THIS THOUGH NOT SURE REQUIRED!

modprobe br_netfilter

cat <<EOF > /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

sysctl --system

# PORTS
firewall-cmd --permanent --add-port=10250/tcp
firewall-cmd --permanent --add-port=30000-32767/tcp
firewall-cmd --reload
systemctl restart firewalld

# FOR NOW
# TODO WED DID ON CONTROLLER TOO
cat <<EOF >>/etc/hosts
192.168.0.46 centos81
192.168.0.47 worker
EOF

# The socat binary enables support for the kubectl port-forward command.
yum -y install socat conntrack ipset

Disable Swap
By default the kubelet will fail to start if swap is enabled

Verify if swap is enabled:

swapon --show
If output is emphy then swap is not enabled. If swap is enabled run the following command to disable swap immediately:

swapoff -a

[[ -z $(swapon --show) ]] && echo swap is already off || { swapoff -a; sed -i '/ swap /d' /etc/fstab; }

# makes it permanent
sed -i '/ swap /d' /etc/fstab


# GET BINARIES

# kubernetes components: kubectl, kube-proxy and kubelet
$ TAG=v1.20.1 && WORKER=192.168.0.47 &&\
  for binary in kubectl kube-proxy kubelet; do\
    curl -s https://storage.googleapis.com/kubernetes-release/release/$TAG/bin/linux/amd64/$binary -o $binary &&\
    chmod +x $binary && scp -i $PROJROOT/servers/id_rsa $binary root@$WORKER:/usr/local/bin/;\
  done

# crictl
TAG=v1.19.0 && CRICTL=crictl-$TAG-linux-amd64.tar.gz && WORKER=192.168.0.47 &&\
 curl -sL https://github.com/kubernetes-sigs/cri-tools/releases/download/$TAG/$CRICTL -o $CRICTL &&\
 cat $CRICTL | ssh -i $PROJROOT/servers/id_rsa root@$WORKER \
 "tar zxvf - --no-same-owner -C /usr/local/bin/ crictl && chmod +x /usr/local/bin/crictl"

# runc
TAG=v1.0.0-rc92 && WORKER=192.168.0.47 &&\
 curl -sL https://github.com/opencontainers/runc/releases/download/$TAG/runc.amd64 -o runc &&\
 chmod +x runc && scp -i $PROJROOT/servers/id_rsa runc root@$WORKER:/usr/local/bin

# cni-plugins
TAG=v0.9.0 && PLUGIN=cni-plugins-linux-amd64-$TAG.tgz && WORKER=192.168.0.47 &&\
 ssh -i $PROJROOT/servers/id_rsa root@$WORKER "mkdir -p /opt/cni/bin" &&\
 curl -sL https://github.com/containernetworking/plugins/releases/download/$TAG/$PLUGIN -o $PLUGIN &&\
 cat $PLUGIN | ssh -i $PROJROOT/servers/id_rsa root@$WORKER "tar zxvf - --no-same-owner -C /opt/cni/bin/"

## TODO look at https://kubernetes.io/docs/setup/production-environment/container-runtimes/
# containerd
TAG=1.4.3 && CONTAINERD=containerd-$TAG-linux-amd64.tar.gz && WORKER=192.168.0.47 &&\
 curl -sL https://github.com/containerd/containerd/releases/download/v$TAG/$CONTAINERD -o $CONTAINERD &&\
 cat $CONTAINERD | ssh -i $PROJROOT/servers/id_rsa root@$WORKER \
 "tar zxvf - --strip-components 1 --no-same-owner -C /bin/ bin"

# TEST:
# IN VM
# ctr image pull docker.io/coredns/coredns:1.8.0


# get the pod CIDR range (hard-coded)
POD_CIDR=10.200.1.0/24

TODO what about https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#letting-iptables-see-bridged-traffic

## TLS
PROJROOT=/home/eace/k8sbyhand

# kubelet cert
# TODO multiple worker support

$ WORKER_IP=192.168.0.47
$ openssl genrsa -out worker-key.pem 2048
# configure the csr config file
$ sed -e "17s|IP.*|IP.1 = $WORKER_IP|" csr.conf >| worker-csr.conf
# create a CSR
$ openssl req -new -key worker-key.pem -out worker.csr -config worker-csr.conf
# gen server certificate using the ca.key, ca.crt and server.csr
$ openssl x509 -req -in worker.csr -CA $PROJROOT/tls/ca.pem -CAkey $PROJROOT/tls/ca-key.pem -CAcreateserial -out worker.pem -days 10000 -extensions v3_ext -extfile worker-csr.conf
# verify
$ openssl x509  -noout -text -in worker.pem
# cleanup
$ rm -f worker.csr worker-csr.conf *.srl

# kubelet config

CONTROLLER_IP=192.168.0.46
kubectl config set-cluster kubernetes \
--certificate-authority=$PROJROOT/tls/ca.pem \
--embed-certs=true \
--server=https://$CONTROLLER_IP:6443 \
--kubeconfig=./worker.kubeconfig

kubectl config set-credentials system:node:worker \
--client-certificate=worker.pem \
--client-key=worker-key.pem \
--embed-certs=true \
--kubeconfig=./worker.kubeconfig

kubectl config set-context default \
--cluster=kubernetes \
--user=system:node:worker \
--kubeconfig=./worker.kubeconfig

kubectl config use-context default --kubeconfig=./worker.kubeconfig

# configure the kubelet
# note a lot of this networking stuff from hightower can be found on
#  https://github.com/containernetworking/cni
# and
# https://github.com/containernetworking/plugins
# "bridge: Creates a bridge, adds the host and the container to it."

ssh -i $PROJROOT/servers/id_rsa root@$WORKER_IP "mkdir -p /var/lib/kubelet/kubeconfig /var/lib/kubernetes /etc/containerd"
scp -i $PROJROOT/servers/id_rsa $PROJROOT/workers/worker.pem root@$WORKER_IP:/var/lib/kubelet/
scp -i $PROJROOT/servers/id_rsa $PROJROOT/workers/worker-key.pem root@$WORKER_IP:/var/lib/kubelet/
scp -i $PROJROOT/servers/id_rsa $PROJROOT/workers/worker.kubeconfig root@$WORKER_IP:/var/lib/kubelet/kubeconfig
scp -i $PROJROOT/servers/id_rsa $PROJROOT/tls/ca.pem root@$WORKER_IP:/var/lib/kubernetes/

scp -i $PROJROOT/servers/id_rsa $PROJROOT/workers/10-bridge.conf root@$WORKER_IP:/etc/cni/net.d/10-bridge.conf
scp -i $PROJROOT/servers/id_rsa $PROJROOT/workers/99-loopback.conf root@$WORKER_IP:/etc/cni/net.d/99-loopback.conf
scp -i $PROJROOT/servers/id_rsa $PROJROOT/workers/containerd-config.toml root@$WORKER_IP:/etc/containerd/config.toml
scp -i $PROJROOT/servers/id_rsa $PROJROOT/workers/containerd.service root@$WORKER_IP:/etc/systemd/system/containerd.service
# TODO hard coded cidr and node name
# TODO also resolveConf setting commented out for centos
scp -i $PROJROOT/servers/id_rsa $PROJROOT/workers/kubelet-config.yaml root@$WORKER_IP:/var/lib/kubelet/kubelet-config.yaml
scp -i $PROJROOT/servers/id_rsa $PROJROOT/workers/kubelet.service root@$WORKER_IP:/etc/systemd/system/kubelet.service


# kube-proxy
# TODO https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/#other-authenticating-components
# TODO run as daemonset?!

# kube proxy cert
# TODO DELETE FROM TLS DIR!
$ openssl req -nodes -newkey rsa:2048 -keyout kube-proxy-key.pem -subj "/CN=system:kube-proxy" -out kube-proxy.csr
$ openssl x509 -req -days 10000 -in kube-proxy.csr -CA $PROJROOT/tls/ca.pem -CAkey $PROJROOT/tls/ca-key.pem -CAcreateserial -sha256 -out kube-proxy.pem
# verify
$ openssl x509 -noout -text -in kube-proxy.pem | less
# cleanup
$ rm -f kube-proxy.csr

# kube-proxy config

kubectl config set-cluster kubernetes \
--certificate-authority=$PROJROOT/tls/ca.pem \
--embed-certs=true \
--server=https://$CONTROLLER_IP:6443 \
--kubeconfig=kube-proxy.kubeconfig

kubectl config set-credentials system:kube-proxy \
--client-certificate=kube-proxy.pem \
--client-key=kube-proxy-key.pem \
--embed-certs=true \
--kubeconfig=kube-proxy.kubeconfig

kubectl config set-context default \
--cluster=kubernetes \
--user=system:kube-proxy \
--kubeconfig=kube-proxy.kubeconfig

kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig

ssh -i $PROJROOT/servers/id_rsa root@$WORKER_IP "mkdir -p /var/lib/kube-proxy /var/lib/kube-proxy/kubeconfig"
scp -i $PROJROOT/servers/id_rsa $PROJROOT/workers/kube-proxy.kubeconfig root@$WORKER_IP:/var/lib/kube-proxy/kubeconfig/
scp -i $PROJROOT/servers/id_rsa $PROJROOT/workers/kube-proxy-config.yaml root@$WORKER_IP:/var/lib/kube-proxy/kube-proxy-config.yaml
scp -i $PROJROOT/servers/id_rsa $PROJROOT/workers/kube-proxy.service root@$WORKER_IP:/etc/systemd/system/kube-proxy.service


ssh -i $PROJROOT/servers/id_rsa root@$WORKER_IP \
 "systemctl daemon-reload && systemctl enable containerd kubelet kube-proxy && systemctl start containerd kubelet kube-proxy"


# from desktop
kubectl get nodes  --kubeconfig worker.kubeconfig
NAME     STATUS   ROLES    AGE   VERSION
worker   Ready    <none>   43s   v1.20.1

SUCCESS!!!!!

<<<< HERE TUE 3:19 AT STEP 10 !!!!!!

# now set up the admin kube config
# on the local workstation

cp $PROJROOT/kubernetes-config-files/admin.kubeconfig ~/.kube/config

kubectl get nodes
kubectl get componentstatuses