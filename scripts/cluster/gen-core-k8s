#!/usr/bin/env bash
#
# Generates the Kubernetes core cluster by installing only the canonical
# Kubernetes controller and worker components in each VM based on the VM's
# ordinal position in the cluster. (Node 0 is a controller+worker, Nodes
# >=1 are workers.)
#

set -e

long_opts=containerized-cplane:,priv-key:,ca-cert:,ca-key:,config:

# api
containerized_cplane=
priv_key=
ca_cert=
ca_key=
config=

#
# option parsing helper
#
function opt_val() {
  opt="$1"
  if [[ "$opt" == =* ]]; then
    echo "${opt:1}"
  else
    echo "$opt"
  fi
}

#
# parses command line parameters and sets script variables from them
#
function parse_args() {
  if [[ "$#" -eq 0 ]]; then
    echo "no args provided"
    exit 1
  fi
  local parsed
  local script_name=$(basename "$0")
  parsed=$(getopt --options "" --longoptions $long_opts -n $script_name -- "$@")
  eval set -- "$parsed"
  while true; do
    case "$1" in
      --containerized-cplane)
        containerized_cplane=$(opt_val "$2")
        shift 2
        ;;
      --priv-key)
        priv_key=$(opt_val "$2")
        shift 2
        ;;
      --ca-cert)
        ca_cert=$(opt_val "$2")
        shift 2
        ;;
      --ca-key)
        ca_key=$(opt_val "$2")
        shift 2
        ;;
      --config)
        config=$(opt_val "$2")
        shift 2
        ;;
      --)
        shift
        break
        ;;
    esac
  done
}

parse_args "$@"

# The control plane node will get the worker components for two reasons: 1) it supports
# a containerized control plane, and 2) it lets the controller be also a worker

vmcnt=$(xec yp $config ?vms)
vm_names=()

for ((i = 0; i < $vmcnt; ++i)); do
  vm_name=$(xec yp $config vms/$i/name)
  pod_cidr=$(xec yp $config vms/$i/pod-cidr)
  vm_ip=$(xec get-vm-ip $vm_name)

  if [[ $i -eq 0 ]]; then
    controller_ip=$vm_ip
    xec gen-admin-kubeconfig --controller-ip=$controller_ip --ca-cert=$ca_cert --ca-key=$ca_key
    admin_kubeconfig=$DTKBASE/generated/kubeconfig/admin.kubeconfig
  fi

  ssh -i $priv_key root@$vm_ip mkdir -p /etc/desktop-kubernetes/static-pods

  xec configure-worker\
   --controller-ip=$controller_ip\
   --worker-hostname=$vm_name\
   --priv-key=$priv_key\
   --admin-kubeconfig=$admin_kubeconfig\
   --pod-cidr=$pod_cidr\
   --ca-cert=$ca_cert\
   --ca-key=$ca_key

  if [[ $i -eq 0 ]]; then
    xec configure-controller\
     --controller-hostname=$vm_name\
     --priv-key=$priv_key\
     --admin-kubeconfig=$admin_kubeconfig\
     --containerized-cplane=$containerized_cplane\
     --ca-cert=$ca_cert\
     --ca-key=$ca_key
  fi

  vm_names+=($vm_name)
done

echo "Waiting for all nodes to be Ready"

for ((i = 0; i < $vmcnt; ++i)); do
  kubectl wait node "${vm_names[$i]}" --for=condition=Ready --timeout=30s
done

echo "Labeling node(s) - first node is controller & worker, all other nodes are workers"

for ((i = 0; i < $vmcnt; ++i)); do
  if [[ $i -eq 0 ]]; then
    labels=(controller worker)
  else
    labels=(worker)
  fi
  for label in "${labels[@]}"; do
    kubectl --kubeconfig $admin_kubeconfig label node "${vm_names[$i]}" node-role.kubernetes.io/$label=
  done
done

echo "Core Kubernetes cluster creation successful"
